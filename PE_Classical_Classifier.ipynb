{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df_train = pd.read_csv('dataset_malwares.csv', sep=',')\n",
    "df_train.reset_index(drop=False, inplace=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Malware Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_magic</th>\n",
       "      <th>e_cblp</th>\n",
       "      <th>e_cp</th>\n",
       "      <th>e_crlc</th>\n",
       "      <th>e_cparhdr</th>\n",
       "      <th>e_minalloc</th>\n",
       "      <th>e_maxalloc</th>\n",
       "      <th>e_ss</th>\n",
       "      <th>e_sp</th>\n",
       "      <th>e_csum</th>\n",
       "      <th>...</th>\n",
       "      <th>SectionMaxChar</th>\n",
       "      <th>SectionMainChar</th>\n",
       "      <th>DirectoryEntryImport</th>\n",
       "      <th>DirectoryEntryImportSize</th>\n",
       "      <th>DirectoryEntryExport</th>\n",
       "      <th>ImageDirectoryEntryExport</th>\n",
       "      <th>ImageDirectoryEntryImport</th>\n",
       "      <th>ImageDirectoryEntryResource</th>\n",
       "      <th>ImageDirectoryEntryException</th>\n",
       "      <th>ImageDirectoryEntrySecurity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.035065</td>\n",
       "      <td>-0.047511</td>\n",
       "      <td>-0.040545</td>\n",
       "      <td>-0.038601</td>\n",
       "      <td>-0.040437</td>\n",
       "      <td>0.148867</td>\n",
       "      <td>-0.016353</td>\n",
       "      <td>-0.033982</td>\n",
       "      <td>-0.029242</td>\n",
       "      <td>...</td>\n",
       "      <td>1.014413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117949</td>\n",
       "      <td>0.394159</td>\n",
       "      <td>-0.091200</td>\n",
       "      <td>-0.015444</td>\n",
       "      <td>-0.074457</td>\n",
       "      <td>-0.070549</td>\n",
       "      <td>-0.019852</td>\n",
       "      <td>-0.040668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.035065</td>\n",
       "      <td>-0.047511</td>\n",
       "      <td>-0.040545</td>\n",
       "      <td>-0.038601</td>\n",
       "      <td>-0.040437</td>\n",
       "      <td>0.148867</td>\n",
       "      <td>-0.016353</td>\n",
       "      <td>-0.033982</td>\n",
       "      <td>-0.029242</td>\n",
       "      <td>...</td>\n",
       "      <td>1.071671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.313968</td>\n",
       "      <td>1.645403</td>\n",
       "      <td>-0.091200</td>\n",
       "      <td>-0.015444</td>\n",
       "      <td>-0.030279</td>\n",
       "      <td>-0.038492</td>\n",
       "      <td>-0.021109</td>\n",
       "      <td>-0.024700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.035065</td>\n",
       "      <td>-0.047511</td>\n",
       "      <td>-0.040545</td>\n",
       "      <td>-0.038601</td>\n",
       "      <td>-0.040437</td>\n",
       "      <td>0.148867</td>\n",
       "      <td>-0.016353</td>\n",
       "      <td>-0.033982</td>\n",
       "      <td>-0.029242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.014942</td>\n",
       "      <td>0.583026</td>\n",
       "      <td>-0.091200</td>\n",
       "      <td>-0.015444</td>\n",
       "      <td>-0.078193</td>\n",
       "      <td>-0.075993</td>\n",
       "      <td>-0.021109</td>\n",
       "      <td>-0.040668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.035065</td>\n",
       "      <td>-0.047511</td>\n",
       "      <td>-0.040545</td>\n",
       "      <td>-0.038601</td>\n",
       "      <td>-0.040437</td>\n",
       "      <td>0.148867</td>\n",
       "      <td>-0.016353</td>\n",
       "      <td>-0.033982</td>\n",
       "      <td>-0.029242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250840</td>\n",
       "      <td>0.417768</td>\n",
       "      <td>-0.091200</td>\n",
       "      <td>-0.015444</td>\n",
       "      <td>-0.010282</td>\n",
       "      <td>0.066146</td>\n",
       "      <td>-0.021109</td>\n",
       "      <td>0.610281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.035065</td>\n",
       "      <td>-0.047511</td>\n",
       "      <td>-0.040545</td>\n",
       "      <td>-0.038601</td>\n",
       "      <td>-0.040437</td>\n",
       "      <td>0.148867</td>\n",
       "      <td>-0.016353</td>\n",
       "      <td>-0.033982</td>\n",
       "      <td>-0.029242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.546506</td>\n",
       "      <td>-0.463612</td>\n",
       "      <td>-0.091200</td>\n",
       "      <td>-0.015444</td>\n",
       "      <td>-0.072969</td>\n",
       "      <td>-0.071154</td>\n",
       "      <td>-0.021109</td>\n",
       "      <td>-0.036487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19606</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.035065</td>\n",
       "      <td>-0.047511</td>\n",
       "      <td>-0.040545</td>\n",
       "      <td>-0.038601</td>\n",
       "      <td>-0.040437</td>\n",
       "      <td>0.148867</td>\n",
       "      <td>-0.016353</td>\n",
       "      <td>-0.033982</td>\n",
       "      <td>-0.029242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250840</td>\n",
       "      <td>-0.133095</td>\n",
       "      <td>-0.091200</td>\n",
       "      <td>-0.015444</td>\n",
       "      <td>-0.080726</td>\n",
       "      <td>-0.077807</td>\n",
       "      <td>-0.021109</td>\n",
       "      <td>-0.040668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19607</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.035065</td>\n",
       "      <td>-0.047511</td>\n",
       "      <td>-0.040545</td>\n",
       "      <td>-0.038601</td>\n",
       "      <td>-0.040437</td>\n",
       "      <td>0.148867</td>\n",
       "      <td>-0.016353</td>\n",
       "      <td>-0.033982</td>\n",
       "      <td>-0.029242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516622</td>\n",
       "      <td>2.274960</td>\n",
       "      <td>-0.091200</td>\n",
       "      <td>-0.015444</td>\n",
       "      <td>0.214412</td>\n",
       "      <td>0.133888</td>\n",
       "      <td>-0.021109</td>\n",
       "      <td>0.829238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19608</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.180936</td>\n",
       "      <td>-0.049587</td>\n",
       "      <td>-0.040545</td>\n",
       "      <td>-0.043228</td>\n",
       "      <td>-0.040437</td>\n",
       "      <td>-7.044462</td>\n",
       "      <td>-0.016353</td>\n",
       "      <td>-0.181223</td>\n",
       "      <td>-0.029242</td>\n",
       "      <td>...</td>\n",
       "      <td>1.014413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.812288</td>\n",
       "      <td>-0.801999</td>\n",
       "      <td>-0.091200</td>\n",
       "      <td>-0.015444</td>\n",
       "      <td>-0.086029</td>\n",
       "      <td>-0.072968</td>\n",
       "      <td>-0.021109</td>\n",
       "      <td>-0.040668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19609</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.035065</td>\n",
       "      <td>-0.047511</td>\n",
       "      <td>-0.040545</td>\n",
       "      <td>-0.038601</td>\n",
       "      <td>-0.040437</td>\n",
       "      <td>0.148867</td>\n",
       "      <td>-0.016353</td>\n",
       "      <td>-0.033982</td>\n",
       "      <td>-0.029242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.782404</td>\n",
       "      <td>0.472854</td>\n",
       "      <td>-0.039572</td>\n",
       "      <td>-0.011363</td>\n",
       "      <td>-0.065856</td>\n",
       "      <td>-0.066920</td>\n",
       "      <td>-0.021109</td>\n",
       "      <td>-0.040668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19610</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.035065</td>\n",
       "      <td>-0.047511</td>\n",
       "      <td>-0.040545</td>\n",
       "      <td>-0.038601</td>\n",
       "      <td>-0.040437</td>\n",
       "      <td>0.148867</td>\n",
       "      <td>-0.016353</td>\n",
       "      <td>-0.033982</td>\n",
       "      <td>-0.029242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.838896</td>\n",
       "      <td>0.976499</td>\n",
       "      <td>0.283104</td>\n",
       "      <td>-0.015061</td>\n",
       "      <td>0.029991</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>-0.021109</td>\n",
       "      <td>-0.040668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19611 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       e_magic    e_cblp      e_cp    e_crlc  e_cparhdr  e_minalloc  \\\n",
       "0          0.0 -0.035065 -0.047511 -0.040545  -0.038601   -0.040437   \n",
       "1          0.0 -0.035065 -0.047511 -0.040545  -0.038601   -0.040437   \n",
       "2          0.0 -0.035065 -0.047511 -0.040545  -0.038601   -0.040437   \n",
       "3          0.0 -0.035065 -0.047511 -0.040545  -0.038601   -0.040437   \n",
       "4          0.0 -0.035065 -0.047511 -0.040545  -0.038601   -0.040437   \n",
       "...        ...       ...       ...       ...        ...         ...   \n",
       "19606      0.0 -0.035065 -0.047511 -0.040545  -0.038601   -0.040437   \n",
       "19607      0.0 -0.035065 -0.047511 -0.040545  -0.038601   -0.040437   \n",
       "19608      0.0 -0.180936 -0.049587 -0.040545  -0.043228   -0.040437   \n",
       "19609      0.0 -0.035065 -0.047511 -0.040545  -0.038601   -0.040437   \n",
       "19610      0.0 -0.035065 -0.047511 -0.040545  -0.038601   -0.040437   \n",
       "\n",
       "       e_maxalloc      e_ss      e_sp    e_csum  ...  SectionMaxChar  \\\n",
       "0        0.148867 -0.016353 -0.033982 -0.029242  ...        1.014413   \n",
       "1        0.148867 -0.016353 -0.033982 -0.029242  ...        1.071671   \n",
       "2        0.148867 -0.016353 -0.033982 -0.029242  ...        0.098279   \n",
       "3        0.148867 -0.016353 -0.033982 -0.029242  ...        0.103647   \n",
       "4        0.148867 -0.016353 -0.033982 -0.029242  ...        0.109015   \n",
       "...           ...       ...       ...       ...  ...             ...   \n",
       "19606    0.148867 -0.016353 -0.033982 -0.029242  ...        0.098279   \n",
       "19607    0.148867 -0.016353 -0.033982 -0.029242  ...        0.098279   \n",
       "19608   -7.044462 -0.016353 -0.181223 -0.029242  ...        1.014413   \n",
       "19609    0.148867 -0.016353 -0.033982 -0.029242  ...        0.098279   \n",
       "19610    0.148867 -0.016353 -0.033982 -0.029242  ...        0.098279   \n",
       "\n",
       "       SectionMainChar  DirectoryEntryImport  DirectoryEntryImportSize  \\\n",
       "0                  0.0              0.117949                  0.394159   \n",
       "1                  0.0              1.313968                  1.645403   \n",
       "2                  0.0             -0.014942                  0.583026   \n",
       "3                  0.0              0.250840                  0.417768   \n",
       "4                  0.0             -0.546506                 -0.463612   \n",
       "...                ...                   ...                       ...   \n",
       "19606              0.0              0.250840                 -0.133095   \n",
       "19607              0.0              0.516622                  2.274960   \n",
       "19608              0.0             -0.812288                 -0.801999   \n",
       "19609              0.0              0.782404                  0.472854   \n",
       "19610              0.0              3.838896                  0.976499   \n",
       "\n",
       "       DirectoryEntryExport  ImageDirectoryEntryExport  \\\n",
       "0                 -0.091200                  -0.015444   \n",
       "1                 -0.091200                  -0.015444   \n",
       "2                 -0.091200                  -0.015444   \n",
       "3                 -0.091200                  -0.015444   \n",
       "4                 -0.091200                  -0.015444   \n",
       "...                     ...                        ...   \n",
       "19606             -0.091200                  -0.015444   \n",
       "19607             -0.091200                  -0.015444   \n",
       "19608             -0.091200                  -0.015444   \n",
       "19609             -0.039572                  -0.011363   \n",
       "19610              0.283104                  -0.015061   \n",
       "\n",
       "       ImageDirectoryEntryImport  ImageDirectoryEntryResource  \\\n",
       "0                      -0.074457                    -0.070549   \n",
       "1                      -0.030279                    -0.038492   \n",
       "2                      -0.078193                    -0.075993   \n",
       "3                      -0.010282                     0.066146   \n",
       "4                      -0.072969                    -0.071154   \n",
       "...                          ...                          ...   \n",
       "19606                  -0.080726                    -0.077807   \n",
       "19607                   0.214412                     0.133888   \n",
       "19608                  -0.086029                    -0.072968   \n",
       "19609                  -0.065856                    -0.066920   \n",
       "19610                   0.029991                     0.000218   \n",
       "\n",
       "       ImageDirectoryEntryException  ImageDirectoryEntrySecurity  \n",
       "0                         -0.019852                    -0.040668  \n",
       "1                         -0.021109                    -0.024700  \n",
       "2                         -0.021109                    -0.040668  \n",
       "3                         -0.021109                     0.610281  \n",
       "4                         -0.021109                    -0.036487  \n",
       "...                             ...                          ...  \n",
       "19606                     -0.021109                    -0.040668  \n",
       "19607                     -0.021109                     0.829238  \n",
       "19608                     -0.021109                    -0.040668  \n",
       "19609                     -0.021109                    -0.040668  \n",
       "19610                     -0.021109                    -0.040668  \n",
       "\n",
       "[19611 rows x 77 columns]"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df_train.drop(['Name', 'Malware', 'index'], axis = 1)\n",
    "y = df_train['Malware']\n",
    "\n",
    "ss = StandardScaler()\n",
    "standardized_data_train = pd.DataFrame(ss.fit_transform(X), columns=X.columns)\n",
    "\n",
    "\n",
    "standardized_data_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction (10, 30, 50 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance sum :  0.9858054682616457\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# Using 10 features\n",
    "pca_10 = PCA(n_components= 10)\n",
    "df_10 = pca_10.fit_transform(standardized_data_train)\n",
    "\n",
    "\n",
    "\n",
    "# Using 30 features\n",
    "pca_30 = PCA(n_components= 30)\n",
    "df_30 = pca_30.fit_transform(standardized_data_train)\n",
    "\n",
    "\n",
    "# Using 50 features\n",
    "pca_55 = PCA(n_components= 55)\n",
    "df_55 = pca_55.fit_transform(standardized_data_train)\n",
    "\n",
    "print('Information retained : ', pca_55.explained_variance_ratio_.cumsum()[-1])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg accuracy of each fold with 10 features: 0.9494672619650981\n",
      "Avg accuracy of each fold with 30 features: 0.9600225550113034\n",
      "Avg accuracy of each fold with 55 features: 0.9625721965690808\n",
      "Avg accuracy of each fold with all features: 0.9599205662300694\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# Model on 10 features\n",
    "LogReg_10 = LogisticRegression(penalty='l1', C=0.1, solver='liblinear', max_iter=100)\n",
    "k_f = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "x = pd.DataFrame(df_10)\n",
    "\n",
    "average_acc = 0\n",
    "\n",
    "for train, test in k_f.split(x):\n",
    "    x_train, x_test = x.iloc[train, :], x.iloc[test, :]\n",
    "    y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "\n",
    "    LogReg_10.fit(x_train, y_train)\n",
    "    predictions = LogReg_10.predict(x_test)\n",
    "\n",
    "    accuracy = accuracy_score(predictions, y_test)\n",
    "\n",
    "    average_acc += accuracy\n",
    "\n",
    "print(\"Avg accuracy of each fold with 10 features: \" + str(average_acc/10))\n",
    "\n",
    "\n",
    "\n",
    "# Model on 30 features\n",
    "LogReg_30 = LogisticRegression(penalty='l1', C=0.1, solver='liblinear', max_iter=100)\n",
    "k_f = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "x = pd.DataFrame(df_30)\n",
    "\n",
    "average_acc = 0\n",
    "\n",
    "for train, test in k_f.split(x):\n",
    "    x_train, x_test = x.iloc[train, :], x.iloc[test, :]\n",
    "    y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "\n",
    "    LogReg_30.fit(x_train, y_train)\n",
    "    predictions = LogReg_30.predict(x_test)\n",
    "\n",
    "    accuracy = accuracy_score(predictions, y_test)\n",
    "\n",
    "    average_acc += accuracy\n",
    "\n",
    "print(\"Avg accuracy of each fold with 30 features: \" + str(average_acc/10))\n",
    "\n",
    "\n",
    "\n",
    "# Model on 50 features\n",
    "LogReg_50 = LogisticRegression(penalty='l1', C=0.1, solver='liblinear', max_iter=50)\n",
    "k_f = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "x = pd.DataFrame(df_55)\n",
    "\n",
    "\n",
    "average_acc = 0\n",
    "\n",
    "for train, test in k_f.split(x):\n",
    "    x_train, x_test = x.iloc[train, :], x.iloc[test, :]\n",
    "    y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "\n",
    "    LogReg_50.fit(x_train, y_train)\n",
    "    predictions = LogReg_50.predict(x_test)\n",
    "\n",
    "    accuracy = accuracy_score(predictions, y_test)\n",
    "\n",
    "    average_acc += accuracy\n",
    "\n",
    "print(\"Avg accuracy of each fold with 55 features: \" + str(average_acc/10))\n",
    "\n",
    "# Model on all features\n",
    "LogReg = LogisticRegression(penalty='l1', C=0.1, solver='liblinear', max_iter=100)\n",
    "k_f = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "x = standardized_data_train\n",
    "\n",
    "average_acc = 0\n",
    "\n",
    "for train, test in k_f.split(x):\n",
    "    x_train, x_test = x.iloc[train, :], x.iloc[test, :]\n",
    "    y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "\n",
    "    LogReg.fit(x_train, y_train)\n",
    "    predictions = LogReg.predict(x_test)\n",
    "\n",
    "    accuracy = accuracy_score(predictions, y_test)\n",
    "\n",
    "    average_acc += accuracy\n",
    "\n",
    "print(\"Avg accuracy of each fold with all features: \" + str(average_acc/10))\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying the 17 Test samples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3rd Logistic Regression Model is the most accurate by utilizing the top 50 features. Let us try classifying the 17 samples in the dataset_test.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skype-8.10.0.9.exe 1 [0.17986113 0.82013887]\n",
      "vlc-3.0.2-win64.exe 1 [8.41536185e-05 9.99915846e-01]\n",
      "stinger32.exe 1 [0.00202075 0.99797925]\n",
      "SpotifyFullSetup.exe 1 [0.33187193 0.66812807]\n",
      "uftp_english.exe 1 [0.06039927 0.93960073]\n",
      "161a59f2525518f799c63f916c80fe85f50c5b09c74dc26ba90c27a87335a6ce 1 [0.04818013 0.95181987]\n",
      "eaa478e65696ad5cbdb42c1b4bd6954f2a876fdde2e5199ea7dbf605642eb3f0 1 [0.04262975 0.95737025]\n",
      "reverse_shell.exe 1 [0.00193994 0.99806006]\n",
      "873b9eaef6ea5ed6126086594529a3395bdbc5d63c97d89de47118c79080104e 1 [0.01952678 0.98047322]\n",
      "ScratchInstaller1.4.exe 1 [0.01300079 0.98699921]\n",
      "69eb27dd3bbf5077dcd795872535b89af9a898254b90adaf5af1a4755bbd90da 1 [0.0089383 0.9910617]\n",
      "3334686141a400bb522824fa6f7faf30614372fe11837aa397c51ffce81abe8f 1 [0.00632966 0.99367034]\n",
      "3ec4cb928846f8298e5a13b3e96bfc2a709cb3b005a31ece81dc67af1e9b3e0a 1 [0.05052556 0.94947444]\n",
      "252f705dc15d7a305afd3e0619fa014c10b679248f71b7ba38f02eed25bec5c6 1 [0.00179387 0.99820613]\n",
      "wordweb8.exe 1 [0.04199055 0.95800945]\n",
      "c89f1e55b418a4447394994498971c6e6f3848bfe39ef9ba6fb255791358b00c 1 [0.01954613 0.98045387]\n",
      "winrar-x64-550.exe 1 [0.05746839 0.94253161]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ashis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but PCA was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('dataset_test.csv', sep=',')\n",
    "df_test.reset_index(drop=False, inplace=True)\n",
    "\n",
    "x = df_55\n",
    "LogReg_55 = LogisticRegression(penalty='l1', C=0.1, solver='liblinear', max_iter=100)\n",
    "LogReg_55.fit(x, y)\n",
    "\n",
    "names = df_test[\"Name\"].values\n",
    "df_test = df_test.drop(['Name', 'index'], axis=1)\n",
    "\n",
    "\n",
    "test_scaled = ss.transform(df_test)\n",
    "test_pca = pca_55.transform(test_scaled)\n",
    "log_test_pred = LogReg_55.predict(test_pca)\n",
    "log_test_prob = LogReg_55.predict_proba(test_pca)\n",
    "\n",
    "\n",
    "\n",
    "for i, v in enumerate(names):\n",
    "    print(v, log_test_pred[i], log_test_prob[i])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key take away here is to understand why the Logistic Regression model does poorly with the test samples. A major reason could be due to the class imbalance that is apparent in the dataset. There appears to be more samples classified as malware as opposed to benign. This could be a factor as class imbalance tends to mess up the precision of Logistic Regression due to it being a linear model. We can instead adopt a Tree based Classifier as these models are known for being a better use case when the dataset is imbalanced."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going between using Decision Tree or Random Forest. Random Forest seems like the way to go just because Random Forest proves to be good in datasets with a lot of features and samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg accuracy of each fold with 55 features: 0.9891896310366104\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "RF_Model = RandomForestClassifier(n_estimators=100, random_state=0, max_depth=10)\n",
    "k_f = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "x = standardized_data_train\n",
    "\n",
    "average_acc = 0\n",
    "\n",
    "for train, test in k_f.split(x):\n",
    "    x_train, x_test = x.iloc[train, :], x.iloc[test, :]\n",
    "    y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "\n",
    "    RF_Model.fit(x_train, y_train)\n",
    "    predictions = RF_Model.predict(x_test)\n",
    "\n",
    "    accuracy = accuracy_score(predictions, y_test)\n",
    "\n",
    "    average_acc += accuracy\n",
    "\n",
    "print(\"Avg accuracy of each fold with 55 features: \" + str(average_acc/10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying 17 samples using Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skype-8.10.0.9.exe 0 [0.98 0.02]\n",
      "vlc-3.0.2-win64.exe 0 [0.77 0.23]\n",
      "stinger32.exe 1 [0.2 0.8]\n",
      "SpotifyFullSetup.exe 0 [0.68 0.32]\n",
      "uftp_english.exe 0 [0.54 0.46]\n",
      "161a59f2525518f799c63f916c80fe85f50c5b09c74dc26ba90c27a87335a6ce 1 [0.15342152 0.84657848]\n",
      "eaa478e65696ad5cbdb42c1b4bd6954f2a876fdde2e5199ea7dbf605642eb3f0 1 [3.54557979e-05 9.99964544e-01]\n",
      "reverse_shell.exe 1 [0.07 0.93]\n",
      "873b9eaef6ea5ed6126086594529a3395bdbc5d63c97d89de47118c79080104e 1 [0.05 0.95]\n",
      "ScratchInstaller1.4.exe 0 [0.53078332 0.46921668]\n",
      "69eb27dd3bbf5077dcd795872535b89af9a898254b90adaf5af1a4755bbd90da 1 [0.05054164 0.94945836]\n",
      "3334686141a400bb522824fa6f7faf30614372fe11837aa397c51ffce81abe8f 1 [3.31697201e-04 9.99668303e-01]\n",
      "3ec4cb928846f8298e5a13b3e96bfc2a709cb3b005a31ece81dc67af1e9b3e0a 1 [6.32197027e-05 9.99936780e-01]\n",
      "252f705dc15d7a305afd3e0619fa014c10b679248f71b7ba38f02eed25bec5c6 1 [0.0307462 0.9692538]\n",
      "wordweb8.exe 1 [0.13005309 0.86994691]\n",
      "c89f1e55b418a4447394994498971c6e6f3848bfe39ef9ba6fb255791358b00c 1 [0.05 0.95]\n",
      "winrar-x64-550.exe 0 [0.62 0.38]\n"
     ]
    }
   ],
   "source": [
    "x = df_55\n",
    "RF_Model = RandomForestClassifier(n_estimators = 100, max_depth = 24)\n",
    "RF_Model.fit(x, y)\n",
    "\n",
    "rf_test_pred = RF_Model.predict(test_pca)\n",
    "rf_test_prob = RF_Model.predict_proba(test_pca)\n",
    "\n",
    "for i, v in enumerate(names):\n",
    "    print(v, rf_test_pred[i], rf_test_prob[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
